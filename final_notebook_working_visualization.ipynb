{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kFSqkTCdWKMI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "4OkrKWRWyMlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "08ad1cb5-8955-4c09-ae14-a06b81d72a61"
      },
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting moviepy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/af/98b68b047c47d9430cb4c9ac899cf9d969de3936f888072991ea74da93a8/moviepy-0.2.3.5.tar.gz (372kB)\n",
            "\u001b[K    100% |████████████████████████████████| 378kB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.3.0)\n",
            "Collecting imageio<3.0,>=2.1.2 (from moviepy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/1d/33c8686072148b3b0fcc12a2e0857dd8316b8ae20a0fa66c8d6a6d01c05c/imageio-2.3.0-py2.py3-none-any.whl (3.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.3MB 8.1MB/s \n",
            "\u001b[?25hCollecting tqdm<5.0,>=4.11.2 (from moviepy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e6/19dfaff08fcbee7f3453e5b537e65a8364f1945f921a36d08be1e2ff3475/tqdm-4.24.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from moviepy) (1.14.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio<3.0,>=2.1.2->moviepy) (0.45.1)\n",
            "Building wheels for collected packages: moviepy\n",
            "  Running setup.py bdist_wheel for moviepy ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/ad/92/4d/a6c6307d4c2219d002646bd4a5987e31fd5697f6ea7778b2c0\n",
            "Successfully built moviepy\n",
            "Installing collected packages: imageio, tqdm, moviepy\n",
            "Successfully installed imageio-2.3.0 moviepy-0.2.3.5 tqdm-4.24.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hV4P5gyTWKMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "dd1fad43-0c71-402a-d864-e7c0b25a4cf6"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Lambda, Conv2D, Activation, Cropping2D, MaxPooling2D, Dropout, Reshape, \\\n",
        "    Convolution2D\n",
        "from moviepy.editor import VideoFileClip\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3194880/45929032 bytes (7.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6750208/45929032 bytes (14.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b10403840/45929032 bytes (22.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b14016512/45929032 bytes (30.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17571840/45929032 bytes (38.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b21151744/45929032 bytes (46.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24723456/45929032 bytes (53.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28188672/45929032 bytes (61.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31793152/45929032 bytes (69.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35405824/45929032 bytes (77.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39010304/45929032 bytes (84.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42516480/45929032 bytes (92.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45883392/45929032 bytes (99.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /content/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wy72mWwAWKMK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualization utils"
      ]
    },
    {
      "metadata": {
        "id": "v7m_NY_aWKMK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import functools\n",
        "\n",
        "_TITLE_LEFT_MARGIN = 10\n",
        "_TITLE_TOP_MARGIN = 10\n",
        "STANDARD_COLORS = [\n",
        "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
        "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
        "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
        "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
        "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
        "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
        "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
        "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
        "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
        "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
        "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
        "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
        "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
        "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
        "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
        "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
        "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
        "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
        "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
        "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
        "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
        "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
        "    'WhiteSmoke', 'Yellow', 'YellowGreen']\n",
        "def visualize_boxes_and_labels_on_image_array(\n",
        "    image,\n",
        "    boxes,\n",
        "    classes,classes1,\n",
        "    scores,scores1,\n",
        "    category_index,category_index1,\n",
        "    instance_masks=None,\n",
        "    instance_boundaries=None,\n",
        "    keypoints=None,\n",
        "    use_normalized_coordinates=False,\n",
        "    max_boxes_to_draw=20,\n",
        "    min_score_thresh=.5,\n",
        "    agnostic_mode=False,\n",
        "    line_thickness=4,\n",
        "    groundtruth_box_visualization_color='black',\n",
        "    skip_scores=False,\n",
        "    skip_labels=False):\n",
        "  \n",
        "  # Create a display string (and color) for every box location, group any boxes\n",
        "  # that correspond to the same location.\n",
        "  box_to_display_str_map = collections.defaultdict(list)\n",
        "  box_to_color_map = collections.defaultdict(str)\n",
        "  box_to_instance_masks_map = {}\n",
        "  box_to_instance_boundaries_map = {}\n",
        "  box_to_keypoints_map = collections.defaultdict(list)\n",
        "  if not max_boxes_to_draw:\n",
        "    max_boxes_to_draw = boxes.shape[0]\n",
        "  for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
        "    if scores is None or scores[i] > min_score_thresh:\n",
        "      box = tuple(boxes[i].tolist())\n",
        "      if instance_masks is not None:\n",
        "        box_to_instance_masks_map[box] = instance_masks[i]\n",
        "      if instance_boundaries is not None:\n",
        "        box_to_instance_boundaries_map[box] = instance_boundaries[i]\n",
        "      if keypoints is not None:\n",
        "        box_to_keypoints_map[box].extend(keypoints[i])\n",
        "      if scores is None:\n",
        "        box_to_color_map[box] = groundtruth_box_visualization_color\n",
        "      else:\n",
        "        display_str = ''\n",
        "        if not skip_labels:\n",
        "          if not agnostic_mode:\n",
        "            if classes[i] in category_index.keys():\n",
        "              class_name = category_index[classes[i]]['name']\n",
        "              class_name1 = category_index1[classes1[i]]['name']\n",
        "            else:\n",
        "              class_name = 'N/A'\n",
        "            display_str = str(class_name)\n",
        "        if not skip_scores:\n",
        "          if not display_str:\n",
        "            display_str = '{}%'.format(int(100*scores[i]))\n",
        "          else:\n",
        "            display_str = '{}: {}%'.format(class_name, int(100*scores[i]))\n",
        "            display_str +=' :: '\n",
        "            display_str += '{}: {}%'.format(class_name1, int(100*scores1[i]))\n",
        "        box_to_display_str_map[box].append(display_str)\n",
        "        \n",
        "        if agnostic_mode:\n",
        "          box_to_color_map[box] = 'DarkOrange'\n",
        "        else:\n",
        "          box_to_color_map[box] = STANDARD_COLORS[\n",
        "              classes[i] % len(STANDARD_COLORS)]\n",
        "\n",
        "  # Draw all boxes onto image.\n",
        "  for box, color in box_to_color_map.items():\n",
        "    ymin, xmin, ymax, xmax = box\n",
        "    if instance_masks is not None:\n",
        "      vis_util.draw_mask_on_image_array(\n",
        "          image,\n",
        "          box_to_instance_masks_map[box],\n",
        "          color=color\n",
        "      )\n",
        "    if instance_boundaries is not None:\n",
        "      vis_util.draw_mask_on_image_array(\n",
        "          image,\n",
        "          box_to_instance_boundaries_map[box],\n",
        "          color='red',\n",
        "          alpha=1.0\n",
        "      )\n",
        "    vis_util.draw_bounding_box_on_image_array(\n",
        "        image,\n",
        "        ymin,\n",
        "        xmin,\n",
        "        ymax,\n",
        "        xmax,\n",
        "        color=color,\n",
        "        thickness=line_thickness,\n",
        "        display_str_list=box_to_display_str_map[box],\n",
        "        use_normalized_coordinates=use_normalized_coordinates)\n",
        "    if keypoints is not None:\n",
        "      vis_util.draw_keypoints_on_image_array(\n",
        "          image,\n",
        "          box_to_keypoints_map[box],\n",
        "          color=color,\n",
        "          radius=line_thickness / 2,\n",
        "          use_normalized_coordinates=use_normalized_coordinates)\n",
        "\n",
        "  return image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r5FNuiRPWKMN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Object detection imports\n",
        "Here are the imports from the object detection module."
      ]
    },
    {
      "metadata": {
        "id": "bm0_uNRnWKMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FishingDetection:\n",
        "    def __init__(self, human_detection_graph_path,\n",
        "                 human_detection_graph_label_path,\n",
        "                 num_classes,\n",
        "                 fishing_classification_graph_path,\n",
        "                 fishing_classification_graph_label_path,\n",
        "                 gear_model_weights_path):\n",
        "        self.__human_detection_graph_path = human_detection_graph_path\n",
        "        self.__human_detection_graph = FishingDetection.load_graph(self.__human_detection_graph_path)\n",
        "        self.__num_classes = num_classes\n",
        "        self.__fishing_classification_graph_path = fishing_classification_graph_path\n",
        "        self.__fishing_classification_graph = FishingDetection.load_inception(self.__fishing_classification_graph_path)\n",
        "        self.__label_map = label_map_util.load_labelmap(human_detection_graph_label_path)\n",
        "        self.__categories = label_map_util.convert_label_map_to_categories(self.__label_map,\n",
        "                                                                           max_num_classes=self.__num_classes,\n",
        "                                                                           use_display_name=True)\n",
        "        self.__category_index = label_map_util.create_category_index(self.__categories)\n",
        "        self.__gear_model = FishingDetection.load_trained_model_keras(gear_model_weights_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def nvidia_net(drop_prob = 0.2):\n",
        "      #create a sequential Model\n",
        "      model = Sequential()\n",
        "\n",
        "      #Add a Cropping layer to trim the unneeded portions of the IMAGE from the feed\n",
        "      #model.add(Cropping2D)\n",
        "      #model.add(Reshape((50,50,3), input_shape=(None,None,3))\n",
        "      model.add(Cropping2D(cropping = ((0, 0), (0,0)), input_shape = (100 ,100 ,3)))\n",
        "\n",
        "      #Normalization Layer\n",
        "      #model.add(Lambda(lambda X_input: (X_input/255.0 - 0.5)))\n",
        "\n",
        "      #Conv2D Layer 1 with 5 x 5 kernal size\n",
        "      #model.add(Convolution2D(nb_filter = 3, nb_row = 5, nb_col = 5))\n",
        "      model.add(Convolution2D(nb_filter = 12, nb_row = 3, nb_col = 3, subsample=(1,1)))\n",
        "      model.add(Activation('relu'))\n",
        "\n",
        "      #Dropout layer\n",
        "      model.add(Dropout(drop_prob))\n",
        "\n",
        "      #Conv2D Layer 2 with 5 x 5 kernal size\n",
        "      #model.add(Convolution2D(nb_filter = 24, nb_row = 5, nb_col = 5))\n",
        "      model.add(Conv2D(nb_filter = 24, nb_row = 3, nb_col = 3,subsample=(2,2)))\n",
        "      model.add(Activation('relu'))\n",
        "\n",
        "      #Conv2D Layer 3 with 5 x 5 kernal size\n",
        "      #model.add(Convolution2D(nb_filter = 36, nb_row = 5, nb_col =  5))\n",
        "      model.add(Conv2D(nb_filter = 36, nb_row = 3, nb_col =  3,subsample=(1,1)))\n",
        "      model.add(Activation('relu'))\n",
        "\n",
        "      #Dropout layer\n",
        "      model.add(Dropout(drop_prob))\n",
        "\n",
        "      #Conv2D Layer 4 with 3 x 3 kernal size\n",
        "      #model.add(Convolution2D(nb_filter = 48, nb_row = 3, nb_col = 3))\n",
        "      model.add(Conv2D(nb_filter = 48, nb_row = 3, nb_col = 3))\n",
        "      model.add(Activation('relu'))\n",
        "\n",
        "      #Conv2D Layer 5 with 3 x 3 kernal size\n",
        "      #model.add(Convolution2D(nb_filter = 48, nb_row = 3, nb_col = 3))\n",
        "      model.add(Conv2D(nb_filter = 64, nb_row = 3, nb_col = 3))\n",
        "      model.add(Activation('relu'))\n",
        "\n",
        "      #flatten layer\n",
        "      #flatten the output from convolution Layer\n",
        "      model.add(Flatten())\n",
        "\n",
        "      #Fully connected layer 1\n",
        "      model.add(Dense(output_dim = 50))\n",
        "\n",
        "      #Fully connected Layer 2\n",
        "      model.add(Dense(output_dim = 25))\n",
        "\n",
        "      #Fully connected Layer 3\n",
        "      model.add(Dense(output_dim = 10))\n",
        "\n",
        "      #output Layers\n",
        "      model.add(Dense(output_dim = 2, activation='softmax') )\n",
        "\n",
        "      return model\n",
        "\n",
        "    @staticmethod\n",
        "    def load_graph(graph_path):\n",
        "        detection_graph = tf.Graph()\n",
        "        with detection_graph.as_default():\n",
        "            od_graph_def = tf.GraphDef()\n",
        "            with tf.gfile.GFile(graph_path, 'rb') as fid:\n",
        "                serialized_graph = fid.read()\n",
        "                od_graph_def.ParseFromString(serialized_graph)\n",
        "                tf.import_graph_def(od_graph_def, name='')\n",
        "        return detection_graph\n",
        "\n",
        "    @staticmethod\n",
        "    def load_inception(graph_path):\n",
        "        graph = tf.Graph()\n",
        "        graph_def = tf.GraphDef()\n",
        "        with open(graph_path, \"rb\") as f:\n",
        "            graph_def.ParseFromString(f.read())\n",
        "        with graph.as_default():\n",
        "            tf.import_graph_def(graph_def)\n",
        "        return graph\n",
        "\n",
        "    def load_image_into_numpy_array(self, image):\n",
        "        (im_width, im_height) = image.size\n",
        "        return np.array(image.getdata()).reshape(\n",
        "            (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "    def run_inference_for_single_image(self,\n",
        "                                       image,\n",
        "                                       graph):\n",
        "        with graph.as_default():\n",
        "            with tf.Session() as sess:\n",
        "                # Get handles to input and output tensors\n",
        "                ops = tf.get_default_graph().get_operations()\n",
        "                all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "                tensor_dict = {}\n",
        "                for key in [\n",
        "                    'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                    'detection_classes', 'detection_masks'\n",
        "                ]:\n",
        "                    tensor_name = key + ':0'\n",
        "                    if tensor_name in all_tensor_names:\n",
        "                        tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                            tensor_name)\n",
        "                if 'detection_masks' in tensor_dict:\n",
        "                    # The following processing is only for single image\n",
        "                    detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "                    detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "                    # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                    real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "                    detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "                    detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "                    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                        detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                    detection_masks_reframed = tf.cast(\n",
        "                        tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                    # Follow the convention by adding back the batch dimension\n",
        "                    tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                        detection_masks_reframed, 0)\n",
        "                image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "                # Run inference\n",
        "                output_dict = sess.run(tensor_dict,\n",
        "                                       feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "                # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "                output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "                output_dict['detection_classes'] = output_dict[\n",
        "                    'detection_classes'][0].astype(np.uint8)\n",
        "                output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "                output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "                if 'detection_masks' in output_dict:\n",
        "                    output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "        return output_dict\n",
        "\n",
        "    def list_files(self, path):\n",
        "        # files = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "        # return files\n",
        "        return glob.glob(path)\n",
        "\n",
        "    def process_files(self,\n",
        "                      list_files,\n",
        "                      label):\n",
        "        output = []\n",
        "        for i in list_files:\n",
        "            temp = []\n",
        "            temp.append(i)\n",
        "            ground_truth = [0, 0]\n",
        "            ground_truth[label] = 1.\n",
        "            temp.append(ground_truth)\n",
        "            output.append(temp)\n",
        "        return output\n",
        "\n",
        "    def read_image(self, path):\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        img = self.make_square(img)\n",
        "        img = img.resize((100, 100), Image.ANTIALIAS)\n",
        "        return np.asarray(img)\n",
        "\n",
        "    def pred_keras(self,\n",
        "                   img):\n",
        "        # print(img)\n",
        "        img = self.make_square(img)\n",
        "        img = img.resize((100, 100), Image.ANTIALIAS)\n",
        "        img = np.asarray(img)\n",
        "        img = (img/255)-0.5\n",
        "        return self.__gear_model.predict(np.expand_dims(img, axis=0))\n",
        "\n",
        "    def make_square(self,\n",
        "                    im,\n",
        "                    min_size=100,\n",
        "                    fill_color=(0, 0, 0, 0)):\n",
        "        im = Image.fromarray(im, 'RGB')\n",
        "        x, y = im.size\n",
        "        size = max(min_size, x, y)\n",
        "        new_im = Image.new('RGB', (size, size), fill_color)\n",
        "        # print((int((size - x) / 2), int(size - y) / 2))\n",
        "        new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
        "        return new_im\n",
        "\n",
        "    @staticmethod\n",
        "    def load_trained_model_keras(weights_path):\n",
        "        model = FishingDetection.nvidia_net()\n",
        "        model.load_weights(weights_path)\n",
        "        return model\n",
        "\n",
        "    def load_labels(self, label_file):\n",
        "        label = []\n",
        "        proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
        "        for l in proto_as_ascii_lines:\n",
        "            label.append(l.rstrip())\n",
        "        return label\n",
        "\n",
        "    def read_tensor_from_image_file(self,\n",
        "                                    image_np,\n",
        "                                    input_height=299,\n",
        "                                    input_width=299,\n",
        "                                    input_mean=0,\n",
        "                                    input_std=255):\n",
        "        input_name = \"file_reader\"\n",
        "        output_name = \"normalized\"\n",
        "        file_reader = image_np\n",
        "        image_reader = tf.convert_to_tensor(image_np, np.uint8)\n",
        "        float_caster = tf.cast(image_reader, tf.float32)\n",
        "        dims_expander = tf.expand_dims(float_caster, 0)\n",
        "        resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
        "        normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
        "        sess = tf.Session()\n",
        "        result = sess.run(normalized)\n",
        "        return result\n",
        "\n",
        "    def pred_tensorflow(self,\n",
        "                        image_np,\n",
        "                        graph,\n",
        "                        input_height=299,\n",
        "                        input_width=299,\n",
        "                        input_mean=0,\n",
        "                        input_std=255):\n",
        "        sess = tf.Session(graph=graph)\n",
        "        # label_file = r'D:\\fishing_detection\\data\\output_labels.txt'\n",
        "        t = self.read_tensor_from_image_file(\n",
        "            image_np,\n",
        "            input_height=input_height,\n",
        "            input_width=input_width,\n",
        "            input_mean=input_mean,\n",
        "            input_std=input_std)\n",
        "        input_name = \"import/\" + \"Placeholder\"\n",
        "        output_name = \"import/\" + \"final_result\"\n",
        "        input_operation = graph.get_operation_by_name(input_name)\n",
        "        output_operation = graph.get_operation_by_name(output_name)\n",
        "        with sess as sess:\n",
        "            results = sess.run(output_operation.outputs[0], {\n",
        "                input_operation.outputs[0]: t\n",
        "            })\n",
        "        results = np.squeeze(results)\n",
        "        return results\n",
        "\n",
        "    def predict_fishing(self, image, boxes, classes, scores):\n",
        "        im_width, im_height = image.size\n",
        "        image_np = self.load_image_into_numpy_array(image)\n",
        "        predictions = {}\n",
        "        predictions['bo'] = []\n",
        "        predictions['res'] = []\n",
        "        predictions['score'] = []\n",
        "        predictions1 = {}\n",
        "        predictions1['bo'] = []\n",
        "        predictions1['res'] = []\n",
        "        predictions1['score'] = []\n",
        "        for i in range(len(boxes)):\n",
        "            if classes[i] == 1 and scores[i] > 0.3:\n",
        "                predictions['bo'].append(boxes[i])\n",
        "                predictions1['bo'].append(boxes[i])\n",
        "                box = tuple(boxes[i].tolist())\n",
        "                ymin, xmin, ymax, xmax = box\n",
        "                ymin = int(ymin * im_height)\n",
        "                xmin = int(xmin * im_width)\n",
        "                ymax = int(ymax * im_height)\n",
        "                xmax = int(xmax * im_width)\n",
        "                roi = image_np[ymin:ymax, xmin:xmax]\n",
        "                # c = pred(cv2.cvtColor(roi, cv2.COLOR_RGB2BGR))\n",
        "                c = self.pred_tensorflow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB), self.__fishing_classification_graph)\n",
        "                d = self.pred_keras(roi)[0]\n",
        "                if (c[0] > 0.5):\n",
        "                    predictions['res'].append(0)\n",
        "                    predictions['score'].append(c[0])\n",
        "                else:\n",
        "                    predictions['res'].append(1)\n",
        "                    predictions['score'].append(c[1])\n",
        "                if (d[0] > 0.5):\n",
        "                    predictions1['res'].append(0)\n",
        "                    predictions1['score'].append(d[0])\n",
        "                else:\n",
        "                    predictions1['res'].append(1)\n",
        "                    predictions1['score'].append(d[1])    \n",
        "        print('predictions',predictions)\n",
        "        print('predictions1',predictions1)\n",
        "        return predictions,predictions1\n",
        "\n",
        "    def pipeline(self, img):\n",
        "        image = Image.fromarray(img)\n",
        "        image_np = self.load_image_into_numpy_array(image)\n",
        "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "        output_dict = self.run_inference_for_single_image(image_np, self.__human_detection_graph)\n",
        "        for i in range(len(output_dict['detection_classes'])):\n",
        "            if output_dict['detection_classes'][i] != 1:\n",
        "                output_dict['detection_scores'][i] = 0.0\n",
        "        predi,predi1 = self.predict_fishing(image, output_dict['detection_boxes'], output_dict['detection_classes'],\n",
        "                                     output_dict['detection_scores'])\n",
        "        category_ind1 = {1: {'id': 1, 'name': 'Geared'}, 0: {'id': 0, 'name': 'Not Geared'}}\n",
        "        category_ind = {1: {'id': 1, 'name': 'Not Fishing'}, 0: {'id': 0, 'name': 'Fishing'}}\n",
        "        visualize_boxes_and_labels_on_image_array(\n",
        "            image_np,\n",
        "            np.asarray(predi['bo'], dtype=np.float32),\n",
        "            predi['res'],predi1['res'],\n",
        "            predi['score'],predi1['score'],\n",
        "            category_ind,category_ind1,\n",
        "            instance_masks=output_dict.get('detection_masks'),\n",
        "            use_normalized_coordinates=True,\n",
        "            line_thickness=4)\n",
        "        return image_np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdyc3gIt6Xze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    INPUT_DIRECTORY = 'input_video'\n",
        "    OUTPUT_DIRECTORY = 'output_video'\n",
        "    INPUT_FILE = 'Catching_tuna_Maldivian_style.mp4'\n",
        "    OUTPUT_FILE = 'result4.mp4'\n",
        "    vid_output = os.path.join(OUTPUT_DIRECTORY, OUTPUT_FILE)\n",
        "    vid_input = os.path.join(INPUT_DIRECTORY, INPUT_FILE)\n",
        "    subclip_start = '00:00:20.50'\n",
        "    subclip_end = '00:00:23.80'\n",
        "    clip = VideoFileClip(vid_input).subclip(subclip_start, subclip_end)\n",
        "\n",
        "    DIRECTORY_NAME = 'models'\n",
        "    MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "    TAR_EXTENSION = '.tar.gz'\n",
        "    MODEL_FILE = MODEL_NAME + TAR_EXTENSION\n",
        "    GRAPH_NAME = 'frozen_inference_graph.pb'\n",
        "    DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "    PATH_TO_FROZEN_GRAPH = os.path.join(DIRECTORY_NAME, MODEL_NAME, GRAPH_NAME)\n",
        "    GEAR_MODEL_PATH = r'colab/model.h5'\n",
        "\n",
        "    # List of the strings that is used to add correct label for each box.\n",
        "    PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
        "\n",
        "    NUM_CLASSES = 90\n",
        "    fishing_detection_graph = os.path.join('models', 'inception_retrained', 'output_graph.pb')\n",
        "    fishing_classification_graph_label_path = os.path.join('data', 'output_labels.txt')\n",
        "    object_detect = FishingDetection(human_detection_graph_path=PATH_TO_FROZEN_GRAPH,\n",
        "                                     human_detection_graph_label_path=PATH_TO_LABELS,\n",
        "                                     num_classes=NUM_CLASSES,\n",
        "                                     fishing_classification_graph_path=fishing_detection_graph,\n",
        "                                     fishing_classification_graph_label_path=fishing_classification_graph_label_path,\n",
        "                                     gear_model_weights_path=GEAR_MODEL_PATH)\n",
        "    vid = clip.fl_image(object_detect.pipeline)\n",
        "    vid.write_videofile(vid_output, audio=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3znRPqDz6j2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3250
        },
        "outputId": "586b1754-ec76-4efa-9f21-4cc4daf5ebcc"
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.15644306, 0.17607833, 0.82251096, 0.3345195 ], dtype=float32), array([0.1137785 , 0.6466236 , 0.79842293, 0.81135726], dtype=float32), array([0.08943304, 0.3895247 , 0.8051671 , 0.5414243 ], dtype=float32), array([0.07140476, 0.8052314 , 0.7943431 , 0.9453165 ], dtype=float32), array([0.20181423, 0.00131959, 0.84252244, 0.13493222], dtype=float32)], 'res': [0, 0, 0, 0, 1], 'score': [0.9841511, 0.9456887, 0.9622137, 0.9975395, 0.60856676]}\n",
            "predictions1 {'bo': [array([0.15644306, 0.17607833, 0.82251096, 0.3345195 ], dtype=float32), array([0.1137785 , 0.6466236 , 0.79842293, 0.81135726], dtype=float32), array([0.08943304, 0.3895247 , 0.8051671 , 0.5414243 ], dtype=float32), array([0.07140476, 0.8052314 , 0.7943431 , 0.9453165 ], dtype=float32), array([0.20181423, 0.00131959, 0.84252244, 0.13493222], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.99999475, 0.99999917, 0.99997294, 0.99977714, 0.9985936]}\n",
            "[MoviePy] >>>> Building video output_video/result4.mp4\n",
            "[MoviePy] Writing video output_video/result4.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  3%|▎         | 1/34 [00:12<06:36, 12.01s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.15644306, 0.17607833, 0.82251096, 0.3345195 ], dtype=float32), array([0.1137785 , 0.6466236 , 0.79842293, 0.81135726], dtype=float32), array([0.08943304, 0.3895247 , 0.8051671 , 0.5414243 ], dtype=float32), array([0.07140476, 0.8052314 , 0.7943431 , 0.9453165 ], dtype=float32), array([0.20181423, 0.00131959, 0.84252244, 0.13493222], dtype=float32)], 'res': [0, 0, 0, 0, 1], 'score': [0.9841511, 0.9456887, 0.9622137, 0.9975395, 0.60856676]}\n",
            "predictions1 {'bo': [array([0.15644306, 0.17607833, 0.82251096, 0.3345195 ], dtype=float32), array([0.1137785 , 0.6466236 , 0.79842293, 0.81135726], dtype=float32), array([0.08943304, 0.3895247 , 0.8051671 , 0.5414243 ], dtype=float32), array([0.07140476, 0.8052314 , 0.7943431 , 0.9453165 ], dtype=float32), array([0.20181423, 0.00131959, 0.84252244, 0.13493222], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.99999475, 0.99999917, 0.99997294, 0.99977714, 0.9985936]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  6%|▌         | 2/34 [00:23<06:21, 11.94s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.12592363, 0.64600253, 0.81025445, 0.8050183 ], dtype=float32), array([0.1650311 , 0.17464933, 0.84175813, 0.33380136], dtype=float32), array([0.11477658, 0.37804365, 0.8163167 , 0.5391908 ], dtype=float32), array([0.08462474, 0.80297625, 0.8086245 , 0.97007334], dtype=float32), array([0.22395694, 0.00118845, 0.865186  , 0.13015217], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9337015, 0.9829154, 0.93259084, 0.9966145, 0.6242204]}\n",
            "predictions1 {'bo': [array([0.12592363, 0.64600253, 0.81025445, 0.8050183 ], dtype=float32), array([0.1650311 , 0.17464933, 0.84175813, 0.33380136], dtype=float32), array([0.11477658, 0.37804365, 0.8163167 , 0.5391908 ], dtype=float32), array([0.08462474, 0.80297625, 0.8086245 , 0.97007334], dtype=float32), array([0.22395694, 0.00118845, 0.865186  , 0.13015217], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.99999964, 0.99999714, 0.9999932, 1.0, 0.98694175]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  9%|▉         | 3/34 [00:35<06:09, 11.90s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.13783309, 0.6474978 , 0.823365  , 0.8109571 ], dtype=float32), array([0.1855824 , 0.17839015, 0.8397337 , 0.3355711 ], dtype=float32), array([0.13519046, 0.37692556, 0.83893657, 0.53239113], dtype=float32), array([0.2543795 , 0.00274706, 0.8759843 , 0.13426441], dtype=float32), array([0.08344755, 0.79906595, 0.815941  , 0.99131536], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.935323, 0.9880717, 0.8583168, 0.8150725, 0.99345016]}\n",
            "predictions1 {'bo': [array([0.13783309, 0.6474978 , 0.823365  , 0.8109571 ], dtype=float32), array([0.1855824 , 0.17839015, 0.8397337 , 0.3355711 ], dtype=float32), array([0.13519046, 0.37692556, 0.83893657, 0.53239113], dtype=float32), array([0.2543795 , 0.00274706, 0.8759843 , 0.13426441], dtype=float32), array([0.08344755, 0.79906595, 0.815941  , 0.99131536], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.99999976, 0.999882, 0.9999987, 0.9984382, 0.99999833]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 12%|█▏        | 4/34 [00:47<05:57, 11.91s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.16981149, 0.17880493, 0.8354111 , 0.33536565], dtype=float32), array([0.12118125, 0.6476345 , 0.802215  , 0.8224658 ], dtype=float32), array([0.1267559 , 0.37376192, 0.8211957 , 0.5302941 ], dtype=float32), array([0.2225647 , 0.00231249, 0.8676276 , 0.13509762], dtype=float32), array([0.07336783, 0.80257124, 0.80862033, 0.993676  ], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9869293, 0.940409, 0.92844045, 0.93359214, 0.98159695]}\n",
            "predictions1 {'bo': [array([0.16981149, 0.17880493, 0.8354111 , 0.33536565], dtype=float32), array([0.12118125, 0.6476345 , 0.802215  , 0.8224658 ], dtype=float32), array([0.1267559 , 0.37376192, 0.8211957 , 0.5302941 ], dtype=float32), array([0.2225647 , 0.00231249, 0.8676276 , 0.13509762], dtype=float32), array([0.07336783, 0.80257124, 0.80862033, 0.993676  ], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.99986446, 0.9999869, 0.99998975, 0.9954196, 0.9999801]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 15%|█▍        | 5/34 [00:59<05:45, 11.93s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.17330551, 0.17896962, 0.83216166, 0.33250153], dtype=float32), array([0.10882473, 0.6485421 , 0.802955  , 0.81957835], dtype=float32), array([0.13583046, 0.3689804 , 0.8089214 , 0.52074873], dtype=float32), array([0.21810499, 0.00233471, 0.84922767, 0.13261159], dtype=float32), array([0.06939507, 0.8174387 , 0.7949976 , 0.9990293 ], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9588142, 0.96377045, 0.67539203, 0.8387204, 0.99398637]}\n",
            "predictions1 {'bo': [array([0.17330551, 0.17896962, 0.83216166, 0.33250153], dtype=float32), array([0.10882473, 0.6485421 , 0.802955  , 0.81957835], dtype=float32), array([0.13583046, 0.3689804 , 0.8089214 , 0.52074873], dtype=float32), array([0.21810499, 0.00233471, 0.84922767, 0.13261159], dtype=float32), array([0.06939507, 0.8174387 , 0.7949976 , 0.9990293 ], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.99967456, 0.9999989, 0.9999795, 0.9993562, 0.99997413]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 18%|█▊        | 6/34 [01:11<05:34, 11.93s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.12733155, 0.6534262 , 0.81589943, 0.8064879 ], dtype=float32), array([0.15452898, 0.16751453, 0.8389181 , 0.32111827], dtype=float32), array([0.09567875, 0.35702127, 0.82466936, 0.5103775 ], dtype=float32), array([0.22441855, 0.00095206, 0.85470235, 0.12723054], dtype=float32), array([0.07405934, 0.8213966 , 0.8132489 , 0.99708116], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.93090844, 0.99331635, 0.92438245, 0.8414168, 0.9732623]}\n",
            "predictions1 {'bo': [array([0.12733155, 0.6534262 , 0.81589943, 0.8064879 ], dtype=float32), array([0.15452898, 0.16751453, 0.8389181 , 0.32111827], dtype=float32), array([0.09567875, 0.35702127, 0.82466936, 0.5103775 ], dtype=float32), array([0.22441855, 0.00095206, 0.85470235, 0.12723054], dtype=float32), array([0.07405934, 0.8213966 , 0.8132489 , 0.99708116], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [1.0, 0.99986136, 0.71754706, 0.9813353, 0.9999999]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 21%|██        | 7/34 [01:23<05:22, 11.93s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.1406857 , 0.65477407, 0.8540603 , 0.8125323 ], dtype=float32), array([0.19032311, 0.16544145, 0.8738829 , 0.3194392 ], dtype=float32), array([0.09109211, 0.35135564, 0.8640781 , 0.5082432 ], dtype=float32), array([0.23826507, 0.0032509 , 0.89144635, 0.13145018], dtype=float32), array([0.1049116 , 0.8218286 , 0.83881664, 0.99686456], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.99438184, 0.97453034, 0.9384654, 0.7954573, 0.98971295]}\n",
            "predictions1 {'bo': [array([0.1406857 , 0.65477407, 0.8540603 , 0.8125323 ], dtype=float32), array([0.19032311, 0.16544145, 0.8738829 , 0.3194392 ], dtype=float32), array([0.09109211, 0.35135564, 0.8640781 , 0.5082432 ], dtype=float32), array([0.23826507, 0.0032509 , 0.89144635, 0.13145018], dtype=float32), array([0.1049116 , 0.8218286 , 0.83881664, 0.99686456], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.9999994, 0.9950062, 0.78750306, 0.994464, 0.99999964]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 24%|██▎       | 8/34 [01:35<05:10, 11.96s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.17726693, 0.6611105 , 0.90302336, 0.8242401 ], dtype=float32), array([0.22560024, 0.16678165, 0.9200165 , 0.324345  ], dtype=float32), array([0.09879258, 0.3542336 , 0.8961226 , 0.51830435], dtype=float32), array([0.2710407 , 0.00362478, 0.9418967 , 0.13804008], dtype=float32), array([0.12184852, 0.8339766 , 0.88926667, 0.99575996], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9837235, 0.99694556, 0.97486126, 0.9115732, 0.98665303]}\n",
            "predictions1 {'bo': [array([0.17726693, 0.6611105 , 0.90302336, 0.8242401 ], dtype=float32), array([0.22560024, 0.16678165, 0.9200165 , 0.324345  ], dtype=float32), array([0.09879258, 0.3542336 , 0.8961226 , 0.51830435], dtype=float32), array([0.2710407 , 0.00362478, 0.9418967 , 0.13804008], dtype=float32), array([0.12184852, 0.8339766 , 0.88926667, 0.99575996], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.9999707, 0.9932615, 0.99824774, 0.99617755, 1.0]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 26%|██▋       | 9/34 [01:47<04:59, 11.98s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.1780301 , 0.6577586 , 0.8951473 , 0.81717336], dtype=float32), array([0.20434684, 0.16283616, 0.8996429 , 0.31978986], dtype=float32), array([0.05961046, 0.35488445, 0.8910477 , 0.52140397], dtype=float32), array([0.25824806, 0.00321317, 0.9106802 , 0.13296032], dtype=float32), array([0.12206578, 0.83470356, 0.88193023, 0.99564934], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.94121313, 0.98979926, 0.97647524, 0.72780275, 0.97301155]}\n",
            "predictions1 {'bo': [array([0.1780301 , 0.6577586 , 0.8951473 , 0.81717336], dtype=float32), array([0.20434684, 0.16283616, 0.8996429 , 0.31978986], dtype=float32), array([0.05961046, 0.35488445, 0.8910477 , 0.52140397], dtype=float32), array([0.25824806, 0.00321317, 0.9106802 , 0.13296032], dtype=float32), array([0.12206578, 0.83470356, 0.88193023, 0.99564934], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.99999845, 0.99725693, 0.9995504, 0.99723333, 1.0]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 29%|██▉       | 10/34 [02:00<04:48, 12.00s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.15718508, 0.6510979 , 0.88496697, 0.80052435], dtype=float32), array([0.18284148, 0.16410843, 0.89408654, 0.31156301], dtype=float32), array([0.04717112, 0.35671914, 0.8918888 , 0.52143925], dtype=float32), array([2.3991513e-01, 8.6738169e-04, 9.0110540e-01, 1.2753229e-01],\n",
            "      dtype=float32), array([0.12831295, 0.8304282 , 0.8763635 , 0.99261945], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.89127237, 0.9992861, 0.99730325, 0.9027452, 0.90342665]}\n",
            "predictions1 {'bo': [array([0.15718508, 0.6510979 , 0.88496697, 0.80052435], dtype=float32), array([0.18284148, 0.16410843, 0.89408654, 0.31156301], dtype=float32), array([0.04717112, 0.35671914, 0.8918888 , 0.52143925], dtype=float32), array([2.3991513e-01, 8.6738169e-04, 9.0110540e-01, 1.2753229e-01],\n",
            "      dtype=float32), array([0.12831295, 0.8304282 , 0.8763635 , 0.99261945], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.99999964, 0.99959606, 1.0, 0.9909841, 1.0]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 32%|███▏      | 11/34 [02:12<04:36, 12.02s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.14343363, 0.649769  , 0.8775248 , 0.795693  ], dtype=float32), array([0.14306259, 0.16320798, 0.878072  , 0.31060535], dtype=float32), array([0.04519576, 0.35599276, 0.877094  , 0.5209407 ], dtype=float32), array([0.11886528, 0.83129567, 0.8838867 , 0.9967862 ], dtype=float32), array([2.32547164e-01, 7.67447054e-05, 8.79664540e-01, 1.19803324e-01],\n",
            "      dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.95273155, 0.99378526, 0.998798, 0.9838791, 0.6467612]}\n",
            "predictions1 {'bo': [array([0.14343363, 0.649769  , 0.8775248 , 0.795693  ], dtype=float32), array([0.14306259, 0.16320798, 0.878072  , 0.31060535], dtype=float32), array([0.04519576, 0.35599276, 0.877094  , 0.5209407 ], dtype=float32), array([0.11886528, 0.83129567, 0.8838867 , 0.9967862 ], dtype=float32), array([2.32547164e-01, 7.67447054e-05, 8.79664540e-01, 1.19803324e-01],\n",
            "      dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.9999782, 0.99990416, 1.0, 1.0, 0.99850875]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 35%|███▌      | 12/34 [02:24<04:24, 12.02s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.13504481, 0.15413044, 0.8707504 , 0.305225  ], dtype=float32), array([0.02667502, 0.34805202, 0.8766142 , 0.51216805], dtype=float32), array([0.12870795, 0.6351658 , 0.87103444, 0.78788376], dtype=float32), array([0.21961755, 0.        , 0.8720109 , 0.10705426], dtype=float32), array([0.11333033, 0.82660496, 0.8859583 , 0.9932091 ], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.99102694, 0.996201, 0.97888947, 0.706005, 0.9896455]}\n",
            "predictions1 {'bo': [array([0.13504481, 0.15413044, 0.8707504 , 0.305225  ], dtype=float32), array([0.02667502, 0.34805202, 0.8766142 , 0.51216805], dtype=float32), array([0.12870795, 0.6351658 , 0.87103444, 0.78788376], dtype=float32), array([0.21961755, 0.        , 0.8720109 , 0.10705426], dtype=float32), array([0.11333033, 0.82660496, 0.8859583 , 0.9932091 ], dtype=float32)], 'res': [1, 0, 1, 1, 1], 'score': [0.99987864, 1.0, 0.999998, 0.97838926, 0.99999964]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 38%|███▊      | 13/34 [02:36<04:12, 12.04s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.1462622 , 0.14836605, 0.8841779 , 0.30356055], dtype=float32), array([0.2275961, 0.       , 0.8915234, 0.1018519], dtype=float32), array([0.0429613 , 0.34485924, 0.8991736 , 0.5017943 ], dtype=float32), array([0.15634248, 0.82664585, 0.89921916, 0.9868779 ], dtype=float32), array([0.15696895, 0.6273671 , 0.8929466 , 0.7724188 ], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.98630303, 0.92662895, 0.9922363, 0.9532817, 0.9660247]}\n",
            "predictions1 {'bo': [array([0.1462622 , 0.14836605, 0.8841779 , 0.30356055], dtype=float32), array([0.2275961, 0.       , 0.8915234, 0.1018519], dtype=float32), array([0.0429613 , 0.34485924, 0.8991736 , 0.5017943 ], dtype=float32), array([0.15634248, 0.82664585, 0.89921916, 0.9868779 ], dtype=float32), array([0.15696895, 0.6273671 , 0.8929466 , 0.7724188 ], dtype=float32)], 'res': [1, 1, 0, 1, 1], 'score': [0.99978465, 0.98946744, 0.9999603, 1.0, 0.9999362]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 41%|████      | 14/34 [02:48<04:01, 12.06s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.1886864 , 0.13969089, 0.9212098 , 0.29736328], dtype=float32), array([0.19120696, 0.61855996, 0.92342496, 0.761408  ], dtype=float32), array([0.20166466, 0.80411077, 0.9482944 , 0.9900826 ], dtype=float32), array([0.23629364, 0.        , 0.92610884, 0.09415025], dtype=float32), array([0.06584823, 0.34288946, 0.93276626, 0.5005456 ], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9906729, 0.9895154, 0.9348564, 0.95831996, 0.9986112]}\n",
            "predictions1 {'bo': [array([0.1886864 , 0.13969089, 0.9212098 , 0.29736328], dtype=float32), array([0.19120696, 0.61855996, 0.92342496, 0.761408  ], dtype=float32), array([0.20166466, 0.80411077, 0.9482944 , 0.9900826 ], dtype=float32), array([0.23629364, 0.        , 0.92610884, 0.09415025], dtype=float32), array([0.06584823, 0.34288946, 0.93276626, 0.5005456 ], dtype=float32)], 'res': [1, 1, 1, 1, 0], 'score': [0.99992836, 0.9999654, 1.0, 0.923555, 0.9976301]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 44%|████▍     | 15/34 [03:01<03:49, 12.07s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.21607542, 0.13630521, 0.95583665, 0.294289  ], dtype=float32), array([0.23817551, 0.7987489 , 0.9839623 , 0.98240465], dtype=float32), array([0.21361291, 0.6118757 , 0.95599174, 0.7590465 ], dtype=float32), array([0.3043111 , 0.        , 0.9444234 , 0.09365623], dtype=float32), array([0.13378447, 0.34203714, 0.95072454, 0.49295598], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.99146456, 0.9462508, 0.9845595, 0.67802685, 0.97469246]}\n",
            "predictions1 {'bo': [array([0.21607542, 0.13630521, 0.95583665, 0.294289  ], dtype=float32), array([0.23817551, 0.7987489 , 0.9839623 , 0.98240465], dtype=float32), array([0.21361291, 0.6118757 , 0.95599174, 0.7590465 ], dtype=float32), array([0.3043111 , 0.        , 0.9444234 , 0.09365623], dtype=float32), array([0.13378447, 0.34203714, 0.95072454, 0.49295598], dtype=float32)], 'res': [1, 1, 1, 1, 0], 'score': [0.99990845, 1.0, 0.9999006, 0.9784896, 0.99993706]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 47%|████▋     | 16/34 [03:12<03:36, 12.05s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.23465532, 0.13824853, 0.9707989 , 0.2991061 ], dtype=float32), array([0.2676286 , 0.79991955, 0.996618  , 0.9839472 ], dtype=float32), array([0.2449998 , 0.6130563 , 0.96348596, 0.75763166], dtype=float32), array([0.17230105, 0.3401416 , 0.96395373, 0.49197662], dtype=float32), array([0.32284132, 0.        , 0.93599594, 0.10398909], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.99575907, 0.95922077, 0.97623956, 0.99453133, 0.82377726]}\n",
            "predictions1 {'bo': [array([0.23465532, 0.13824853, 0.9707989 , 0.2991061 ], dtype=float32), array([0.2676286 , 0.79991955, 0.996618  , 0.9839472 ], dtype=float32), array([0.2449998 , 0.6130563 , 0.96348596, 0.75763166], dtype=float32), array([0.17230105, 0.3401416 , 0.96395373, 0.49197662], dtype=float32), array([0.32284132, 0.        , 0.93599594, 0.10398909], dtype=float32)], 'res': [1, 1, 1, 0, 1], 'score': [0.9997634, 1.0, 0.9999702, 0.9999918, 0.96376705]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 17/34 [03:24<03:24, 12.02s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.2245318 , 0.15004212, 0.962145  , 0.30333394], dtype=float32), array([0.16974506, 0.3411551 , 0.9673983 , 0.4918098 ], dtype=float32), array([0.23998684, 0.61626095, 0.9635168 , 0.75994533], dtype=float32), array([0.2707957 , 0.8031505 , 0.99605393, 0.9901168 ], dtype=float32), array([0.29443076, 0.        , 0.9490768 , 0.09968645], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9967163, 0.9440407, 0.9922976, 0.9713778, 0.96183705]}\n",
            "predictions1 {'bo': [array([0.2245318 , 0.15004212, 0.962145  , 0.30333394], dtype=float32), array([0.16974506, 0.3411551 , 0.9673983 , 0.4918098 ], dtype=float32), array([0.23998684, 0.61626095, 0.9635168 , 0.75994533], dtype=float32), array([0.2707957 , 0.8031505 , 0.99605393, 0.9901168 ], dtype=float32), array([0.29443076, 0.        , 0.9490768 , 0.09968645], dtype=float32)], 'res': [1, 0, 1, 1, 1], 'score': [0.9994355, 0.96514636, 0.9999206, 1.0, 0.9480427]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 53%|█████▎    | 18/34 [03:36<03:12, 12.01s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.21091193, 0.15584739, 0.93839103, 0.31062233], dtype=float32), array([0.18079495, 0.35003313, 0.9667816 , 0.5062821 ], dtype=float32), array([0.21474642, 0.62592876, 0.97308403, 0.78990674], dtype=float32), array([0.24101976, 0.8218777 , 0.9876373 , 0.9911792 ], dtype=float32), array([0.2557035 , 0.        , 0.93614763, 0.10434102], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9879615, 0.959348, 0.65361553, 0.95784396, 0.9698335]}\n",
            "predictions1 {'bo': [array([0.21091193, 0.15584739, 0.93839103, 0.31062233], dtype=float32), array([0.18079495, 0.35003313, 0.9667816 , 0.5062821 ], dtype=float32), array([0.21474642, 0.62592876, 0.97308403, 0.78990674], dtype=float32), array([0.24101976, 0.8218777 , 0.9876373 , 0.9911792 ], dtype=float32), array([0.2557035 , 0.        , 0.93614763, 0.10434102], dtype=float32)], 'res': [1, 0, 1, 1, 1], 'score': [0.99980456, 0.9990934, 0.99999475, 1.0, 0.98693556]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 56%|█████▌    | 19/34 [03:48<03:00, 12.02s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.19482043, 0.16267604, 0.9381739 , 0.31213883], dtype=float32), array([0.19856375, 0.35919234, 0.9664288 , 0.51452506], dtype=float32), array([0.24239114, 0.8213327 , 0.97697043, 0.9905461 ], dtype=float32), array([0.21869758, 0.6131148 , 0.9570428 , 0.7660617 ], dtype=float32), array([0.24979982, 0.        , 0.92402875, 0.10034533], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.97097516, 0.9160071, 0.67391676, 0.8334676, 0.94793046]}\n",
            "predictions1 {'bo': [array([0.19482043, 0.16267604, 0.9381739 , 0.31213883], dtype=float32), array([0.19856375, 0.35919234, 0.9664288 , 0.51452506], dtype=float32), array([0.24239114, 0.8213327 , 0.97697043, 0.9905461 ], dtype=float32), array([0.21869758, 0.6131148 , 0.9570428 , 0.7660617 ], dtype=float32), array([0.24979982, 0.        , 0.92402875, 0.10034533], dtype=float32)], 'res': [1, 0, 1, 1, 1], 'score': [0.99991107, 0.9836896, 1.0, 0.9999949, 0.9489439]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 59%|█████▉    | 20/34 [04:00<02:48, 12.01s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.18014762, 0.16313058, 0.93604517, 0.3124889 ], dtype=float32), array([0.23633552, 0.3616214 , 0.9600618 , 0.5144592 ], dtype=float32), array([0.209739  , 0.62684584, 0.9767957 , 0.7892518 ], dtype=float32), array([0.2640865 , 0.8228238 , 0.9781004 , 0.98999125], dtype=float32), array([0.23592347, 0.        , 0.924882  , 0.09196068], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9862055, 0.97114545, 0.7827514, 0.9130898, 0.8290765]}\n",
            "predictions1 {'bo': [array([0.18014762, 0.16313058, 0.93604517, 0.3124889 ], dtype=float32), array([0.23633552, 0.3616214 , 0.9600618 , 0.5144592 ], dtype=float32), array([0.209739  , 0.62684584, 0.9767957 , 0.7892518 ], dtype=float32), array([0.2640865 , 0.8228238 , 0.9781004 , 0.98999125], dtype=float32), array([0.23592347, 0.        , 0.924882  , 0.09196068], dtype=float32)], 'res': [1, 0, 1, 1, 1], 'score': [0.99994767, 0.9996848, 0.99999785, 0.99979466, 0.72066087]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 62%|██████▏   | 21/34 [04:11<02:35, 11.99s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.17156366, 0.16147576, 0.95065963, 0.3129763 ], dtype=float32), array([0.25483647, 0.36148027, 0.9739777 , 0.5169742 ], dtype=float32), array([0.21723253, 0.6272724 , 0.97405905, 0.78846806], dtype=float32), array([0.25126132, 0.81852436, 0.97427976, 0.9947759 ], dtype=float32), array([0.25077724, 0.        , 0.94682586, 0.10031916], dtype=float32)], 'res': [0, 0, 0, 1, 0], 'score': [0.98175836, 0.9821468, 0.87042916, 0.744874, 0.8946904]}\n",
            "predictions1 {'bo': [array([0.17156366, 0.16147576, 0.95065963, 0.3129763 ], dtype=float32), array([0.25483647, 0.36148027, 0.9739777 , 0.5169742 ], dtype=float32), array([0.21723253, 0.6272724 , 0.97405905, 0.78846806], dtype=float32), array([0.25126132, 0.81852436, 0.97427976, 0.9947759 ], dtype=float32), array([0.25077724, 0.        , 0.94682586, 0.10031916], dtype=float32)], 'res': [1, 0, 1, 1, 1], 'score': [0.99995863, 0.9999708, 0.9999957, 1.0, 0.87342566]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 65%|██████▍   | 22/34 [04:23<02:23, 11.98s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.28280595, 0.3582583 , 0.96364856, 0.50854635], dtype=float32), array([0.1772514 , 0.16074574, 0.9544533 , 0.3044643 ], dtype=float32), array([0.26507545, 0.8204032 , 0.99258196, 0.9913595 ], dtype=float32), array([0.2988123 , 0.        , 0.9368681 , 0.10257021], dtype=float32), array([0.2266072, 0.6254428, 0.9838034, 0.7838411], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9803505, 0.9684142, 0.7169548, 0.80586714, 0.90778166]}\n",
            "predictions1 {'bo': [array([0.28280595, 0.3582583 , 0.96364856, 0.50854635], dtype=float32), array([0.1772514 , 0.16074574, 0.9544533 , 0.3044643 ], dtype=float32), array([0.26507545, 0.8204032 , 0.99258196, 0.9913595 ], dtype=float32), array([0.2988123 , 0.        , 0.9368681 , 0.10257021], dtype=float32), array([0.2266072, 0.6254428, 0.9838034, 0.7838411], dtype=float32)], 'res': [0, 1, 1, 1, 1], 'score': [0.99997246, 0.9999995, 1.0, 0.9727985, 0.99999607]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 68%|██████▊   | 23/34 [04:35<02:11, 11.96s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.29502586, 0.34769678, 0.9764389 , 0.4989127 ], dtype=float32), array([0.18207052, 0.14925227, 0.9618069 , 0.29545924], dtype=float32), array([0.25567156, 0.6088438 , 0.9839652 , 0.765743  ], dtype=float32), array([0.26578036, 0.803654  , 0.99734867, 0.9847966 ], dtype=float32), array([3.4440452e-01, 2.0902604e-04, 9.5002347e-01, 1.0396193e-01],\n",
            "      dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.9050819, 0.96316326, 0.93135107, 0.9938261, 0.7230567]}\n",
            "predictions1 {'bo': [array([0.29502586, 0.34769678, 0.9764389 , 0.4989127 ], dtype=float32), array([0.18207052, 0.14925227, 0.9618069 , 0.29545924], dtype=float32), array([0.25567156, 0.6088438 , 0.9839652 , 0.765743  ], dtype=float32), array([0.26578036, 0.803654  , 0.99734867, 0.9847966 ], dtype=float32), array([3.4440452e-01, 2.0902604e-04, 9.5002347e-01, 1.0396193e-01],\n",
            "      dtype=float32)], 'res': [0, 1, 1, 1, 1], 'score': [0.9998765, 0.9999932, 0.9999988, 1.0, 0.9919477]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 71%|███████   | 24/34 [04:45<01:58, 11.88s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.29843572, 0.60826313, 1.        , 0.7621883 ], dtype=float32), array([0.35528243, 0.34497178, 0.9929949 , 0.49009836], dtype=float32), array([0.21570766, 0.14108327, 1.        , 0.29585063], dtype=float32), array([0.2962742, 0.7919921, 1.       , 0.9811056], dtype=float32)], 'res': [0, 0, 0, 0], 'score': [0.9885894, 0.96717167, 0.981076, 0.9636466]}\n",
            "predictions1 {'bo': [array([0.29843572, 0.60826313, 1.        , 0.7621883 ], dtype=float32), array([0.35528243, 0.34497178, 0.9929949 , 0.49009836], dtype=float32), array([0.21570766, 0.14108327, 1.        , 0.29585063], dtype=float32), array([0.2962742, 0.7919921, 1.       , 0.9811056], dtype=float32)], 'res': [1, 0, 1, 1], 'score': [0.99999857, 0.9987029, 0.9996724, 0.9999987]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 74%|███████▎  | 25/34 [04:55<01:46, 11.81s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.31370237, 0.61238325, 0.9992205 , 0.761744  ], dtype=float32), array([0.2911152 , 0.13877045, 1.        , 0.29144716], dtype=float32), array([0.31265503, 0.79199517, 1.        , 0.99170566], dtype=float32), array([0.37304425, 0.3470853 , 1.        , 0.49841732], dtype=float32)], 'res': [0, 0, 0, 0], 'score': [0.669167, 0.790119, 0.9653957, 0.9686622]}\n",
            "predictions1 {'bo': [array([0.31370237, 0.61238325, 0.9992205 , 0.761744  ], dtype=float32), array([0.2911152 , 0.13877045, 1.        , 0.29144716], dtype=float32), array([0.31265503, 0.79199517, 1.        , 0.99170566], dtype=float32), array([0.37304425, 0.3470853 , 1.        , 0.49841732], dtype=float32)], 'res': [1, 1, 1, 0], 'score': [0.9999976, 0.99903286, 1.0, 0.9998747]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 76%|███████▋  | 26/34 [05:05<01:33, 11.74s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.3204245, 0.6096473, 0.9974919, 0.7624699], dtype=float32), array([0.32501522, 0.7937034 , 1.        , 0.9817987 ], dtype=float32), array([0.38496733, 0.34668463, 0.99880064, 0.4946841 ], dtype=float32), array([0.24583438, 0.13914552, 1.        , 0.29328874], dtype=float32)], 'res': [1, 0, 0, 0], 'score': [0.6125418, 0.88687176, 0.78107876, 0.9394948]}\n",
            "predictions1 {'bo': [array([0.3204245, 0.6096473, 0.9974919, 0.7624699], dtype=float32), array([0.32501522, 0.7937034 , 1.        , 0.9817987 ], dtype=float32), array([0.38496733, 0.34668463, 0.99880064, 0.4946841 ], dtype=float32), array([0.24583438, 0.13914552, 1.        , 0.29328874], dtype=float32)], 'res': [1, 1, 0, 1], 'score': [0.9999994, 1.0, 0.9997782, 0.999985]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 79%|███████▉  | 27/34 [05:13<01:21, 11.63s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.30634448, 0.6153354 , 1.        , 0.7585948 ], dtype=float32), array([0.38016784, 0.34930438, 0.99709344, 0.49527234], dtype=float32), array([0.30817443, 0.80217767, 1.        , 0.9773449 ], dtype=float32)], 'res': [1, 0, 0], 'score': [0.6335973, 0.8586606, 0.9449022]}\n",
            "predictions1 {'bo': [array([0.30634448, 0.6153354 , 1.        , 0.7585948 ], dtype=float32), array([0.38016784, 0.34930438, 0.99709344, 0.49527234], dtype=float32), array([0.30817443, 0.80217767, 1.        , 0.9773449 ], dtype=float32)], 'res': [1, 0, 1], 'score': [0.9999491, 0.99983215, 1.0]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 82%|████████▏ | 28/34 [05:23<01:09, 11.57s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.30513427, 0.6130813 , 0.9961966 , 0.7610032 ], dtype=float32), array([0.28917584, 0.80046403, 1.        , 0.9744625 ], dtype=float32), array([0.3779438 , 0.35293922, 0.9965938 , 0.50260335], dtype=float32), array([0.14426094, 0.13592961, 0.9959999 , 0.31279302], dtype=float32)], 'res': [0, 0, 1, 1], 'score': [0.98885405, 0.9611897, 0.59480006, 0.5476785]}\n",
            "predictions1 {'bo': [array([0.30513427, 0.6130813 , 0.9961966 , 0.7610032 ], dtype=float32), array([0.28917584, 0.80046403, 1.        , 0.9744625 ], dtype=float32), array([0.3779438 , 0.35293922, 0.9965938 , 0.50260335], dtype=float32), array([0.14426094, 0.13592961, 0.9959999 , 0.31279302], dtype=float32)], 'res': [1, 1, 0, 1], 'score': [0.99999964, 1.0, 0.9999727, 0.9943131]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 85%|████████▌ | 29/34 [05:34<00:57, 11.52s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.35795468, 0.3498662 , 0.98088247, 0.5088961 ], dtype=float32), array([0.13110471, 0.13632458, 0.98137045, 0.31852913], dtype=float32), array([0.25700644, 0.8172267 , 0.99028945, 0.9955421 ], dtype=float32), array([0.2621062 , 0.62689686, 0.9831327 , 0.7762711 ], dtype=float32)], 'res': [0, 0, 0, 0], 'score': [0.57506484, 0.77325636, 0.8666581, 0.9978502]}\n",
            "predictions1 {'bo': [array([0.35795468, 0.3498662 , 0.98088247, 0.5088961 ], dtype=float32), array([0.13110471, 0.13632458, 0.98137045, 0.31852913], dtype=float32), array([0.25700644, 0.8172267 , 0.99028945, 0.9955421 ], dtype=float32), array([0.2621062 , 0.62689686, 0.9831327 , 0.7762711 ], dtype=float32)], 'res': [0, 1, 1, 1], 'score': [0.9999882, 0.99923694, 0.9999999, 0.99999785]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 30/34 [05:45<00:46, 11.52s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.3155684 , 0.36584023, 0.96319944, 0.5094886 ], dtype=float32), array([0.25731835, 0.6308917 , 0.94040084, 0.78678155], dtype=float32), array([0.        , 0.13290192, 0.95088154, 0.3285249 ], dtype=float32), array([0.22704336, 0.82066953, 0.96457696, 0.9930594 ], dtype=float32), array([0.2546289 , 0.6309485 , 0.61337733, 0.7658765 ], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.83656037, 0.98175585, 0.9864486, 0.7563537, 0.8908423]}\n",
            "predictions1 {'bo': [array([0.3155684 , 0.36584023, 0.96319944, 0.5094886 ], dtype=float32), array([0.25731835, 0.6308917 , 0.94040084, 0.78678155], dtype=float32), array([0.        , 0.13290192, 0.95088154, 0.3285249 ], dtype=float32), array([0.22704336, 0.82066953, 0.96457696, 0.9930594 ], dtype=float32), array([0.2546289 , 0.6309485 , 0.61337733, 0.7658765 ], dtype=float32)], 'res': [0, 1, 1, 1, 0], 'score': [0.99998987, 0.99999976, 0.9975448, 1.0, 0.9977436]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 31/34 [05:57<00:34, 11.52s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.3206502 , 0.36830163, 0.9655392 , 0.5109719 ], dtype=float32), array([0.2558542 , 0.628286  , 0.93927187, 0.78891444], dtype=float32), array([0.2552768 , 0.6292596 , 0.61949414, 0.76246905], dtype=float32), array([0.22832301, 0.8193787 , 0.9650836 , 0.9966133 ], dtype=float32), array([0.04905847, 0.12805822, 0.9867077 , 0.3272877 ], dtype=float32)], 'res': [0, 0, 0, 0, 0], 'score': [0.867672, 0.96724105, 0.85501915, 0.88699687, 0.9937628]}\n",
            "predictions1 {'bo': [array([0.3206502 , 0.36830163, 0.9655392 , 0.5109719 ], dtype=float32), array([0.2558542 , 0.628286  , 0.93927187, 0.78891444], dtype=float32), array([0.2552768 , 0.6292596 , 0.61949414, 0.76246905], dtype=float32), array([0.22832301, 0.8193787 , 0.9650836 , 0.9966133 ], dtype=float32), array([0.04905847, 0.12805822, 0.9867077 , 0.3272877 ], dtype=float32)], 'res': [0, 1, 0, 1, 1], 'score': [0.99997747, 0.999997, 0.71646774, 1.0, 0.9966557]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 32/34 [06:05<00:22, 11.43s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.35245612, 0.34236357, 0.97261274, 0.49492136], dtype=float32), array([0.25943103, 0.8029947 , 0.9795356 , 0.9668089 ], dtype=float32), array([0.2636318, 0.6051346, 0.9714868, 0.7700151], dtype=float32)], 'res': [0, 0, 0], 'score': [0.8681155, 0.91393805, 0.8338729]}\n",
            "predictions1 {'bo': [array([0.35245612, 0.34236357, 0.97261274, 0.49492136], dtype=float32), array([0.25943103, 0.8029947 , 0.9795356 , 0.9668089 ], dtype=float32), array([0.2636318, 0.6051346, 0.9714868, 0.7700151], dtype=float32)], 'res': [0, 1, 1], 'score': [0.99984396, 1.0, 0.9999999]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 33/34 [06:14<00:11, 11.35s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.34834787, 0.3407216 , 0.97030926, 0.49915844], dtype=float32), array([0.2690855 , 0.7964202 , 0.97374606, 0.95489705], dtype=float32), array([0.2502787 , 0.62398255, 0.968012  , 0.78657556], dtype=float32)], 'res': [0, 0, 0], 'score': [0.96084803, 0.9199438, 0.9853078]}\n",
            "predictions1 {'bo': [array([0.34834787, 0.3407216 , 0.97030926, 0.49915844], dtype=float32), array([0.2690855 , 0.7964202 , 0.97374606, 0.95489705], dtype=float32), array([0.2502787 , 0.62398255, 0.968012  , 0.78657556], dtype=float32)], 'res': [0, 1, 1], 'score': [0.99999034, 0.9258729, 0.99998915]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "100%|██████████| 34/34 [06:24<00:00, 11.31s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions {'bo': [array([0.32757196, 0.33786654, 0.95788693, 0.4980197 ], dtype=float32), array([0.2547668 , 0.80061895, 0.9627379 , 0.95526344], dtype=float32), array([0.25533107, 0.6032059 , 0.9437411 , 0.7687228 ], dtype=float32), array([0.27828664, 0.8615422 , 0.9650852 , 0.9876051 ], dtype=float32)], 'res': [0, 0, 0, 0], 'score': [0.9156188, 0.88096255, 0.9625453, 0.77684605]}\n",
            "predictions1 {'bo': [array([0.32757196, 0.33786654, 0.95788693, 0.4980197 ], dtype=float32), array([0.2547668 , 0.80061895, 0.9627379 , 0.95526344], dtype=float32), array([0.25533107, 0.6032059 , 0.9437411 , 0.7687228 ], dtype=float32), array([0.27828664, 0.8615422 , 0.9650852 , 0.9876051 ], dtype=float32)], 'res': [0, 1, 1, 1], 'score': [0.99999595, 0.99977154, 0.999848, 1.0]}\n",
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: output_video/result4.mp4 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "utyZfEoCJ5iN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('output_video/result4.mp4') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3TGvVYlC0gcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4b7f5ac3-29bc-4b98-fee9-6fa7f79ce9ce"
      },
      "cell_type": "code",
      "source": [
        "predictions = {}\n",
        "predictions['bo'] = []\n",
        "predictions['res'] = []\n",
        "predictions['score'] = []\n",
        "predictions1= predictions\n",
        "predictions1['score']=12\n",
        "print(predictions1['score'])\n",
        "print(predictions['score'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}